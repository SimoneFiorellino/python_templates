task_name: "train"

defaults:
  - _self_
  - model: mnist
  - datamodule: mnist

seed: 42

paths:
  root_dir: .
  data_dir: ${paths.root_dir}/data/
  log_dir: ${paths.root_dir}/logs/
  output_dir: ${hydra:runtime.output_dir}
  work_dir: ${hydra:runtime.cwd}

hydra:
  run:
    dir: ${paths.log_dir}/${task_name}/runs/${now:%Y-%m-%d}_${now:%H-%M-%S}
  sweep:
    dir: ${paths.log_dir}/${task_name}/multiruns/${now:%Y-%m-%d}_${now:%H-%M-%S}
    subdir: ${hydra.job.num}

trainer:
  _target_: pytorch_lightning.Trainer
  min_epochs: 1
  max_epochs: 2
  accelerator: gpu
  devices: [0]
  check_val_every_n_epoch: 1
  deterministic: False
  # limit_train_batches: 1.0

logger:
  _target_: pytorch_lightning.loggers.wandb.WandbLogger
  save_dir: "logs"
  offline: True # <---------------------------------------------------------------------------------------
  id: null # pass correct id to resume experiment!
  anonymous: null # enable anonymous logging
  project: "template"
  log_model: False # upload lightning ckpts
  prefix: "" # a string to put at the beginning of metric keys
  # entity: "" # set to name of your wandb team
  group: ""
  tags: []
  job_type: ""